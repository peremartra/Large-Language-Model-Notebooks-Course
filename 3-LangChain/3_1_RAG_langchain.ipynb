{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/Large-Language-Model-Notebooks-Course/blob/main/3-LangChain/3_1_RAG_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<h1>Large Language Models Projects</h1>\n",
        "    <h3>Apply and Implement Strategies for Large Language Models</h3>\n",
        "    <h2>3.1-Use the Data from your DataFrames with LLMs.</h2>\n",
        "    \n",
        "</div>\n",
        "\n",
        "by [Pere Martra](https://www.linkedin.com/in/pere-martra/)\n",
        "\n",
        "_______________\n",
        "Models: dolly-v2-3b / flan-t5-large\n",
        "\n",
        "Colab Environmet: CPU - High RAM\n",
        "\n",
        "Keys:\n",
        "* RAG\n",
        "* LangChain\n",
        "* Embeddings\n",
        "* LCEL\n",
        "_________________\n",
        "\n",
        "If you are executing this notebook on Colab you will need a High RAM capacity environment.\n",
        "\n",
        "If you don't have a Colab Pro acoount you can execute this notebook on kaggle, since you will get more memory from the free tier."
      ],
      "metadata": {
        "id": "6JEdfdtDgfaz"
      },
      "id": "6JEdfdtDgfaz"
    },
    {
      "cell_type": "markdown",
      "id": "b863e355",
      "metadata": {
        "papermill": {
          "duration": 0.01084,
          "end_time": "2023-11-07T23:38:48.872411",
          "exception": false,
          "start_time": "2023-11-07T23:38:48.861571",
          "status": "completed"
        },
        "tags": [],
        "id": "b863e355"
      },
      "source": [
        "# TUTORIAL HOW TO USE LANGCHAIN AND VECTOR DATABASES TO USE OUR OWN DOCUMENTS WITH HUGGING FACES\n",
        "\n",
        "In a [previous notebook](https://www.kaggle.com/code/peremartramanonellas/use-a-vectorial-db-to-optimize-prompts-for-llms), we saw how to use a vectorial database to create an enriched prompt for Hugging Face language models. In this one, we incorporate LangChain so that we can make queries to the language model that take into account our information.\n",
        "\n",
        "The information could be our own documents, or whatever was contained in a business knowledge database.\n",
        "\n",
        "I have prepared the notebook so that it can work with  different Kaggle datasets, so that it is easy to carry out different tests with different Datasets.\n",
        "\n",
        "The data has been loaded from a Pandas DataFrame, using the **DataFrameLoader** function from the **document_loaders** library of **LangChain**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bac2f0d",
      "metadata": {
        "papermill": {
          "duration": 0.010703,
          "end_time": "2023-11-07T23:38:48.894198",
          "exception": false,
          "start_time": "2023-11-07T23:38:48.883495",
          "status": "completed"
        },
        "tags": [],
        "id": "5bac2f0d"
      },
      "source": [
        "# Install and load the libraries.\n",
        "To start we need to install the necesary Python packages.\n",
        "* **[langchain](https://python.langchain.com/docs/get_started/introduction.html)**. The revolutionary framework to build apps using large language models.\n",
        "* **[sentence_transformers](https://www.sbert.net/)**. necesary to create the embeddings we are going to store in the vector database.  \n",
        "* **[chromadb](https://www.trychroma.com/)**. This is our vector Database. ChromaDB is easy to use and open source, maybe the most used Vector Database used to store embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecaf9c5",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-11-07T23:38:48.918551Z",
          "iopub.status.busy": "2023-11-07T23:38:48.917508Z",
          "iopub.status.idle": "2023-11-07T23:40:10.466442Z",
          "shell.execute_reply": "2023-11-07T23:40:10.465295Z"
        },
        "papermill": {
          "duration": 81.563917,
          "end_time": "2023-11-07T23:40:10.469187",
          "exception": false,
          "start_time": "2023-11-07T23:38:48.90527",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "1ecaf9c5",
        "outputId": "502a6e6e-4523-4d89-9e73-46c37693417c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q chromadb==0.4.22\n",
        "!pip install -q langchain==0.1.4\n",
        "!pip install -q sentence_transformers==2.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f407d757",
      "metadata": {
        "papermill": {
          "duration": 0.022555,
          "end_time": "2023-11-07T23:40:10.609309",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.586754",
          "status": "completed"
        },
        "tags": [],
        "id": "f407d757"
      },
      "source": [
        "# Load the Dataset\n",
        "As you can see the notebook is ready to work with different Datasets. Just uncomment the lines of the Dataset you want to use.\n",
        "\n",
        "As we are working in a free and limited space, and we can use just some limited gb of memory I limited the number of news to use with the variable MAX_NEWS.\n",
        "\n",
        "The name of the field containing the text of the new is stored in the variable *DOCUMENT* and the metadata in *TOPIC*\n",
        "\n",
        "I used the kotartemiy/topic-labeled-news-dataset https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset\n",
        "\n",
        "Artem Burgara. (2020). R vs. Python: Topic Labeled News Dataset, . Retrieved December 2023, from https://www.kaggle.com/discussions/general/46091.\n",
        "\n",
        "But you can ose other datasets, I encourage you to try at least one of these:\n",
        "\n",
        "https://www.kaggle.com/datasets/gpreda/bbc-news\n",
        "\n",
        "https://www.kaggle.com/datasets/deepanshudalal09/mit-ai-news-published-till-2023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conecting to Kaggle."
      ],
      "metadata": {
        "id": "OakH4pOdQrlo"
      },
      "id": "OakH4pOdQrlo"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QV09oMxbZayb",
        "outputId": "47c9f426-a772-45b7-ce8f-f33726201aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QV09oMxbZayb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "7nOpQ8StZk9W"
      },
      "id": "7nOpQ8StZk9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#This directory should contain you kaggle.json file with your key\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'"
      ],
      "metadata": {
        "id": "-FH7rMgFZ0rm"
      },
      "id": "-FH7rMgFZ0rm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kotartemiy/topic-labeled-news-dataset\n",
        "#!kaggle datasets download -d gpreda/bbc-news"
      ],
      "metadata": {
        "id": "F7A8FzbcZ3t6",
        "outputId": "023e6a75-7fcc-4694-90f5-02c9e367174c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F7A8FzbcZ3t6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading topic-labeled-news-dataset.zip to /content\n",
            " 85% 8.00M/9.45M [00:01<00:00, 12.7MB/s]\n",
            "100% 9.45M/9.45M [00:01<00:00, 8.75MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ea9d7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:10.558175Z",
          "iopub.status.busy": "2023-11-07T23:40:10.55769Z",
          "iopub.status.idle": "2023-11-07T23:40:10.562952Z",
          "shell.execute_reply": "2023-11-07T23:40:10.561864Z"
        },
        "papermill": {
          "duration": 0.030688,
          "end_time": "2023-11-07T23:40:10.565135",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.534447",
          "status": "completed"
        },
        "tags": [],
        "id": "09ea9d7c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define the path to your zip file\n",
        "file_path = '/content/topic-labeled-news-dataset.zip'\n",
        "#file_path = '/content/bbc-news.zip'"
      ],
      "metadata": {
        "id": "OPZ3TbXlaWXV"
      },
      "id": "OPZ3TbXlaWXV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/kaggle')"
      ],
      "metadata": {
        "id": "seBuoNVuaaTw"
      },
      "id": "seBuoNVuaaTw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34403557",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:10.653256Z",
          "iopub.status.busy": "2023-11-07T23:40:10.652861Z",
          "iopub.status.idle": "2023-11-07T23:40:11.635339Z",
          "shell.execute_reply": "2023-11-07T23:40:11.634406Z"
        },
        "papermill": {
          "duration": 1.007443,
          "end_time": "2023-11-07T23:40:11.637872",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.630429",
          "status": "completed"
        },
        "tags": [],
        "id": "34403557"
      },
      "outputs": [],
      "source": [
        "news = pd.read_csv('/content/drive/MyDrive/kaggle/labelled_newscatcher_dataset.csv', sep=';')\n",
        "MAX_NEWS = 1000\n",
        "DOCUMENT=\"title\"\n",
        "TOPIC=\"topic\"\n",
        "\n",
        "#news = pd.read_csv('/content/drive/MyDrive/kaggle/bbc_news.csv')\n",
        "#MAX_NEWS = 500\n",
        "#DOCUMENT=\"description\"\n",
        "#TOPIC=\"title\"\n",
        "\n",
        "#Because it is just a course we select a small portion of News.\n",
        "subset_news = news.head(MAX_NEWS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b2f5bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:11.682843Z",
          "iopub.status.busy": "2023-11-07T23:40:11.682429Z",
          "iopub.status.idle": "2023-11-07T23:40:11.703593Z",
          "shell.execute_reply": "2023-11-07T23:40:11.702566Z"
        },
        "papermill": {
          "duration": 0.046286,
          "end_time": "2023-11-07T23:40:11.705855",
          "exception": false,
          "start_time": "2023-11-07T23:40:11.659569",
          "status": "completed"
        },
        "tags": [],
        "id": "87b2f5bd",
        "outputId": "86a30252-add3-4455-9d81-23b1ecae7598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     topic                                               link          domain  \\\n",
              "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
              "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
              "\n",
              "        published_date                                              title lang  \n",
              "0  2020-08-06 13:59:45  A closer look at water-splitting's solar fuel ...   en  \n",
              "1  2020-08-12 15:14:19  An irresistible scent makes locusts swarm, stu...   en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deff4ff1-d2f8-4191-b24f-db3aa5a9361c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>link</th>\n",
              "      <th>domain</th>\n",
              "      <th>published_date</th>\n",
              "      <th>title</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
              "      <td>eurekalert.org</td>\n",
              "      <td>2020-08-06 13:59:45</td>\n",
              "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
              "      <td>pulse.ng</td>\n",
              "      <td>2020-08-12 15:14:19</td>\n",
              "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deff4ff1-d2f8-4191-b24f-db3aa5a9361c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deff4ff1-d2f8-4191-b24f-db3aa5a9361c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deff4ff1-d2f8-4191-b24f-db3aa5a9361c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09bc0dc3-12fd-4f53-b1e3-660c6c5d1f3b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09bc0dc3-12fd-4f53-b1e3-660c6c5d1f3b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09bc0dc3-12fd-4f53-b1e3-660c6c5d1f3b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "news.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ef4e81",
      "metadata": {
        "papermill": {
          "duration": 0.021487,
          "end_time": "2023-11-07T23:40:11.748796",
          "exception": false,
          "start_time": "2023-11-07T23:40:11.727309",
          "status": "completed"
        },
        "tags": [],
        "id": "25ef4e81"
      },
      "source": [
        "## CREATE THE DOCUMENT FROM THE DATAFRAME\n",
        "We are going to load the data from a pandas DataFrame. However, LangChain, through the **document_loader** library, supports multiple data sources, such as Word documents, Excel files, plain text, SQL, and more.\n",
        "\n",
        "We also imported the Chroma library, which is used to save the embeddings in the ChromaDB database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6f1238",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:11.793285Z",
          "iopub.status.busy": "2023-11-07T23:40:11.792911Z",
          "iopub.status.idle": "2023-11-07T23:40:12.353535Z",
          "shell.execute_reply": "2023-11-07T23:40:12.352343Z"
        },
        "papermill": {
          "duration": 0.585876,
          "end_time": "2023-11-07T23:40:12.35627",
          "exception": false,
          "start_time": "2023-11-07T23:40:11.770394",
          "status": "completed"
        },
        "tags": [],
        "id": "4c6f1238"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.vectorstores import Chroma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb88b124",
      "metadata": {
        "papermill": {
          "duration": 0.021508,
          "end_time": "2023-11-07T23:40:12.399239",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.377731",
          "status": "completed"
        },
        "tags": [],
        "id": "eb88b124"
      },
      "source": [
        "First, we create the loader, indicating the data source and the name of the column in the DataFrame where we store what we could consider as the document, that is, the information we want to pass to the model so that it takes it into account in its responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78614daa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.444219Z",
          "iopub.status.busy": "2023-11-07T23:40:12.443484Z",
          "iopub.status.idle": "2023-11-07T23:40:12.449168Z",
          "shell.execute_reply": "2023-11-07T23:40:12.447976Z"
        },
        "papermill": {
          "duration": 0.030632,
          "end_time": "2023-11-07T23:40:12.451276",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.420644",
          "status": "completed"
        },
        "tags": [],
        "id": "78614daa"
      },
      "outputs": [],
      "source": [
        "df_loader = DataFrameLoader(subset_news, page_content_column=DOCUMENT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e777e3ec",
      "metadata": {
        "papermill": {
          "duration": 0.02084,
          "end_time": "2023-11-07T23:40:12.4936",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.47276",
          "status": "completed"
        },
        "tags": [],
        "id": "e777e3ec"
      },
      "source": [
        "Then, we use the loader to load the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0b81fd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.537857Z",
          "iopub.status.busy": "2023-11-07T23:40:12.537404Z",
          "iopub.status.idle": "2023-11-07T23:40:12.652204Z",
          "shell.execute_reply": "2023-11-07T23:40:12.650913Z"
        },
        "papermill": {
          "duration": 0.140406,
          "end_time": "2023-11-07T23:40:12.65498",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.514574",
          "status": "completed"
        },
        "tags": [],
        "id": "1d0b81fd"
      },
      "outputs": [],
      "source": [
        "df_document = df_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948950f7",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.700437Z",
          "iopub.status.busy": "2023-11-07T23:40:12.699647Z",
          "iopub.status.idle": "2023-11-07T23:40:12.759691Z",
          "shell.execute_reply": "2023-11-07T23:40:12.758871Z"
        },
        "papermill": {
          "duration": 0.10378,
          "end_time": "2023-11-07T23:40:12.780315",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.676535",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "948950f7",
        "outputId": "9b1ccdff-c919-4cc7-a9f3-205f2228d494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Document(page_content=\"A closer look at water-splitting's solar fuel potential\", metadata={'topic': 'SCIENCE', 'link': 'https://www.eurekalert.org/pub_releases/2020-08/dbnl-acl080620.php', 'domain': 'eurekalert.org', 'published_date': '2020-08-06 13:59:45', 'lang': 'en'}),\n",
              " Document(page_content='An irresistible scent makes locusts swarm, study finds', metadata={'topic': 'SCIENCE', 'link': 'https://www.pulse.ng/news/world/an-irresistible-scent-makes-locusts-swarm-study-finds/jy784jw', 'domain': 'pulse.ng', 'published_date': '2020-08-12 15:14:19', 'lang': 'en'})]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_document[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82937c96",
      "metadata": {
        "papermill": {
          "duration": 0.026601,
          "end_time": "2023-11-07T23:40:12.833936",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.807335",
          "status": "completed"
        },
        "tags": [],
        "id": "82937c96"
      },
      "source": [
        "# Creating the embeddings\n",
        "First, we import a couple of libraries.\n",
        "* CharacterTextSplitter: we will use it to group the information contained in different blocks.\n",
        "* HuggingFaceEmbeddings: it will create the embeddings in the format that we will store in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6963280e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.889831Z",
          "iopub.status.busy": "2023-11-07T23:40:12.888855Z",
          "iopub.status.idle": "2023-11-07T23:40:12.893122Z",
          "shell.execute_reply": "2023-11-07T23:40:12.892384Z"
        },
        "papermill": {
          "duration": 0.034128,
          "end_time": "2023-11-07T23:40:12.895046",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.860918",
          "status": "completed"
        },
        "tags": [],
        "id": "6963280e"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "#from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b102d83f",
      "metadata": {
        "papermill": {
          "duration": 0.026522,
          "end_time": "2023-11-07T23:40:12.948396",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.921874",
          "status": "completed"
        },
        "tags": [],
        "id": "b102d83f"
      },
      "source": [
        "As I said above we split the data into manageable chunks to store as vectors using **CharacterTextSplitter**. There isn't an exact way to do this, more chunks means more detailed context, but will increase the size of our vectorstore.\n",
        "\n",
        "There are no magic numbers to inform. It is important to consider that the larger the chunk size, the more context the model will have, but the size of our vector store will also increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316f5b14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:13.004502Z",
          "iopub.status.busy": "2023-11-07T23:40:13.003754Z",
          "iopub.status.idle": "2023-11-07T23:40:13.04734Z",
          "shell.execute_reply": "2023-11-07T23:40:13.046217Z"
        },
        "papermill": {
          "duration": 0.07506,
          "end_time": "2023-11-07T23:40:13.050342",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.975282",
          "status": "completed"
        },
        "tags": [],
        "id": "316f5b14"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=10)\n",
        "texts = text_splitter.split_documents(df_document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c982e5e",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:13.106064Z",
          "iopub.status.busy": "2023-11-07T23:40:13.105457Z",
          "iopub.status.idle": "2023-11-07T23:40:13.160232Z",
          "shell.execute_reply": "2023-11-07T23:40:13.158852Z"
        },
        "papermill": {
          "duration": 0.103411,
          "end_time": "2023-11-07T23:40:13.18066",
          "exception": false,
          "start_time": "2023-11-07T23:40:13.077249",
          "status": "completed"
        },
        "tags": [],
        "id": "7c982e5e",
        "outputId": "ac42cf20-65ee-4e9d-ab70-0b855f6f8781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Document(page_content=\"A closer look at water-splitting's solar fuel potential\", metadata={'topic': 'SCIENCE', 'link': 'https://www.eurekalert.org/pub_releases/2020-08/dbnl-acl080620.php', 'domain': 'eurekalert.org', 'published_date': '2020-08-06 13:59:45', 'lang': 'en'}),\n",
              " Document(page_content='An irresistible scent makes locusts swarm, study finds', metadata={'topic': 'SCIENCE', 'link': 'https://www.pulse.ng/news/world/an-irresistible-scent-makes-locusts-swarm-study-finds/jy784jw', 'domain': 'pulse.ng', 'published_date': '2020-08-12 15:14:19', 'lang': 'en'})]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(texts[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779e3387",
      "metadata": {
        "papermill": {
          "duration": 0.03243,
          "end_time": "2023-11-07T23:40:13.245472",
          "exception": false,
          "start_time": "2023-11-07T23:40:13.213042",
          "status": "completed"
        },
        "tags": [],
        "id": "779e3387"
      },
      "source": [
        "We load the library to create the pre trained model from HuggingFace to create the embeddings from sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa973ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:13.31152Z",
          "iopub.status.busy": "2023-11-07T23:40:13.310846Z",
          "iopub.status.idle": "2023-11-07T23:40:31.996557Z",
          "shell.execute_reply": "2023-11-07T23:40:31.995022Z"
        },
        "papermill": {
          "duration": 18.721786,
          "end_time": "2023-11-07T23:40:31.999291",
          "exception": false,
          "start_time": "2023-11-07T23:40:13.277505",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "7fa973ac",
        "outputId": "0898af45-3e70-47cb-cd07-859afbe1d043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea58c45e",
      "metadata": {
        "papermill": {
          "duration": 0.034795,
          "end_time": "2023-11-07T23:40:32.069162",
          "exception": false,
          "start_time": "2023-11-07T23:40:32.034367",
          "status": "completed"
        },
        "tags": [],
        "id": "ea58c45e"
      },
      "source": [
        "# Creating the Index With Chroma\n",
        "Here we are creating the index of embeddings. Using the document, and the embedding function created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eadc6d53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:32.142168Z",
          "iopub.status.busy": "2023-11-07T23:40:32.140958Z",
          "iopub.status.idle": "2023-11-07T23:40:40.614344Z",
          "shell.execute_reply": "2023-11-07T23:40:40.613017Z"
        },
        "papermill": {
          "duration": 8.512528,
          "end_time": "2023-11-07T23:40:40.616895",
          "exception": false,
          "start_time": "2023-11-07T23:40:32.104367",
          "status": "completed"
        },
        "tags": [],
        "id": "eadc6d53"
      },
      "outputs": [],
      "source": [
        "directory_cdb = '/content/drive/MyDrive/chromadb'\n",
        "chroma_db = Chroma.from_documents(\n",
        "    texts, embedding_function, persist_directory=directory_cdb\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708820c5",
      "metadata": {
        "papermill": {
          "duration": 0.034723,
          "end_time": "2023-11-07T23:40:40.687547",
          "exception": false,
          "start_time": "2023-11-07T23:40:40.652824",
          "status": "completed"
        },
        "tags": [],
        "id": "708820c5"
      },
      "source": [
        "## LANGCHAIN\n",
        "\n",
        "Finally, the time has come to create our chain with LangChain. It will be straightforward. All we do is give it a retriever and a model to call with the result obtained from the retriever.\n",
        "\n",
        "Now we are going to import RetrievalQA and HuggingFacePipeline classes from langchain module.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae871f01",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:40.762362Z",
          "iopub.status.busy": "2023-11-07T23:40:40.761944Z",
          "iopub.status.idle": "2023-11-07T23:40:42.256159Z",
          "shell.execute_reply": "2023-11-07T23:40:42.254902Z"
        },
        "papermill": {
          "duration": 1.534176,
          "end_time": "2023-11-07T23:40:42.258996",
          "exception": false,
          "start_time": "2023-11-07T23:40:40.72482",
          "status": "completed"
        },
        "tags": [],
        "id": "ae871f01"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "#from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da545337",
      "metadata": {
        "papermill": {
          "duration": 0.035218,
          "end_time": "2023-11-07T23:40:42.330255",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.295037",
          "status": "completed"
        },
        "tags": [],
        "id": "da545337"
      },
      "source": [
        "Now we create the retriever object, the responsible to return the data contained in the ChromaDB Database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8478f13",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:42.40325Z",
          "iopub.status.busy": "2023-11-07T23:40:42.402545Z",
          "iopub.status.idle": "2023-11-07T23:40:42.408031Z",
          "shell.execute_reply": "2023-11-07T23:40:42.406852Z"
        },
        "papermill": {
          "duration": 0.04437,
          "end_time": "2023-11-07T23:40:42.410217",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.365847",
          "status": "completed"
        },
        "tags": [],
        "id": "a8478f13"
      },
      "outputs": [],
      "source": [
        "retriever = chroma_db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eadae843",
      "metadata": {
        "papermill": {
          "duration": 0.03539,
          "end_time": "2023-11-07T23:40:42.481519",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.446129",
          "status": "completed"
        },
        "tags": [],
        "id": "eadae843"
      },
      "source": [
        "I tested the notebook with two models from Fugging Face.\n",
        "\n",
        "The first one is [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b), the smallest Dolly model. It have 3billion paramaters, more than enough for our sample, and works much better than GPT2. It's a text generation model, and therefore generates slightly more imaginative responses.\n",
        "\n",
        "The second one is a t5 model. This is a text2text-generation. so it will produce more concise and succinct responses.\n",
        "\n",
        "Just be sure the test both, and if you want select other models from Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fe7021",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:42.554566Z",
          "iopub.status.busy": "2023-11-07T23:40:42.554143Z",
          "iopub.status.idle": "2023-11-07T23:40:42.559719Z",
          "shell.execute_reply": "2023-11-07T23:40:42.558545Z"
        },
        "papermill": {
          "duration": 0.044891,
          "end_time": "2023-11-07T23:40:42.561978",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.517087",
          "status": "completed"
        },
        "tags": [],
        "id": "94fe7021"
      },
      "outputs": [],
      "source": [
        "model_id = \"databricks/dolly-v2-3b\" #a good textgeneration model for testing\n",
        "task=\"text-generation\"\n",
        "\n",
        "#model_id = \"google/flan-t5-large\" #Nice text2text model\n",
        "#task=\"text2text-generation\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bef59f8",
      "metadata": {
        "papermill": {
          "duration": 0.03455,
          "end_time": "2023-11-07T23:40:42.631714",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.597164",
          "status": "completed"
        },
        "tags": [],
        "id": "4bef59f8"
      },
      "source": [
        "We use HuggingFacePipeline class to create a pipeline for a specific Hugging Face language model. Let's break down the code:\n",
        "\n",
        "* **model_id**: This is the ID of the Hugging Face language model you want to use. It typically consists of the model name and version.\n",
        "* **task**: This parameter specifies the task that you want to perform using the language model. It could be \"text-generation\", \"text2text-generation\", \"question-answering\", or other tasks supported by the model.\n",
        "* **model_kwargs**: Allows you to provide additional arguments specific to the chosen model. In this case, it sets \"temperature\" to 0 (indicating deterministic output) and \"max_length\" to 256, which limits the maximum length of generated text to 256 tokens.\n",
        "* **pipeline_kwargs**: Allows you to provide extra information related to the pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdfec13",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:42.704032Z",
          "iopub.status.busy": "2023-11-07T23:40:42.703576Z",
          "iopub.status.idle": "2023-11-07T23:42:17.458434Z",
          "shell.execute_reply": "2023-11-07T23:42:17.456989Z"
        },
        "papermill": {
          "duration": 94.79476,
          "end_time": "2023-11-07T23:42:17.461674",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.666914",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "0bdfec13",
        "outputId": "588d7a01-f5c9-49b5-f08e-95d493437c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "#If you want to test the  T5 model remove the return_full_text parameter in pipeline_kwargs,\n",
        "#also I recommend to add model_kwargs and change the temperature.\n",
        "#    model_kwargs={\n",
        "#        \"temperature\": 0,\n",
        "#        \"max_length\": 256\n",
        "#    },\n",
        "hf_llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=model_id,\n",
        "    task=task,\n",
        "    pipeline_kwargs={\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"repetition_penalty\":1.1,\n",
        "        \"return_full_text\":True\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc16f20",
      "metadata": {
        "papermill": {
          "duration": 0.03792,
          "end_time": "2023-11-07T23:42:17.537572",
          "exception": false,
          "start_time": "2023-11-07T23:42:17.499652",
          "status": "completed"
        },
        "tags": [],
        "id": "5cc16f20"
      },
      "source": [
        "We are setting up the ***document_qa***, a **RetrievalQA** object, that we are going to use to run the questions.\n",
        "\n",
        "The ***stuff*** type is the simplest type of chain that we can have. I get the documents from the retiever and use the language model to obtain responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa608d67",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:42:17.61509Z",
          "iopub.status.busy": "2023-11-07T23:42:17.61441Z",
          "iopub.status.idle": "2023-11-07T23:42:17.621618Z",
          "shell.execute_reply": "2023-11-07T23:42:17.620446Z"
        },
        "papermill": {
          "duration": 0.049131,
          "end_time": "2023-11-07T23:42:17.623996",
          "exception": false,
          "start_time": "2023-11-07T23:42:17.574865",
          "status": "completed"
        },
        "tags": [],
        "id": "aa608d67"
      },
      "outputs": [],
      "source": [
        "document_qa = RetrievalQA.from_chain_type(\n",
        "    llm=hf_llm, retriever=retriever, chain_type='stuff'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83a8eca",
      "metadata": {
        "papermill": {
          "duration": 0.0364,
          "end_time": "2023-11-07T23:42:17.696923",
          "exception": false,
          "start_time": "2023-11-07T23:42:17.660523",
          "status": "completed"
        },
        "tags": [],
        "id": "c83a8eca"
      },
      "source": [
        "Time to call the chain and obtain the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25c34f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:42:17.772278Z",
          "iopub.status.busy": "2023-11-07T23:42:17.771797Z",
          "iopub.status.idle": "2023-11-07T23:43:36.092127Z",
          "shell.execute_reply": "2023-11-07T23:43:36.090889Z"
        },
        "papermill": {
          "duration": 78.397935,
          "end_time": "2023-11-07T23:43:36.131687",
          "exception": false,
          "start_time": "2023-11-07T23:42:17.733752",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "f25c34f0",
        "outputId": "91126027-bb57-4be6-ba52-b14be2278cce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'query': 'Can I buy a Toshiba laptop?',\n",
              " 'result': ' No, Toshiba laptops have been discontinued.\\n\\n'}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Sample question for newscatcher dataset.\n",
        "response = document_qa.invoke(\"Can I buy a Toshiba laptop?\")\n",
        "\n",
        "#Sample question for BBC Dataset.\n",
        "#response = document_qa.run(\"Who is going to meet boris johnson?\")\n",
        "display(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the new LCEL Architecture from LangChain.\n",
        "LangChain recommends using LCEL (LangChain Expression Language) over Chains. I'm using both methods in the notebook, but please note that LCEL is the recommended approach."
      ],
      "metadata": {
        "id": "0nVxkDzLSMgr"
      },
      "id": "0nVxkDzLSMgr"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "template = \"\"\"Answer the question based on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "ZtlFB5UhSMNl"
      },
      "id": "ZtlFB5UhSMNl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "HwaLFCjxSpHF"
      },
      "id": "HwaLFCjxSpHF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Can I buy a Toshiba laptop?\")"
      ],
      "metadata": {
        "id": "1RpaUJjhSp9y",
        "outputId": "df051d4f-3c18-4a55-8f7e-5e3476679284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "1RpaUJjhSp9y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: No, Toshiba officially done with making laptops\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the cosine distance between sentences.\n",
        "\n",
        "Bonus section: As you may know, vector databases find the most relevant information to a user's question by measuring the distance between embeddings.\n",
        "\n",
        "Here's a brief example to illustrate how this works."
      ],
      "metadata": {
        "id": "mwSm-uLnaY3k"
      },
      "id": "mwSm-uLnaY3k"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_s1 = embedding_function.embed_query(\n",
        "    \"I would like to eat more vegetables and exercise every day\")\n",
        "\n",
        "embedding_s2 = embedding_function.embed_query(\n",
        "    \"I will try to maintain a healthier lifestyle.\")\n",
        "\n",
        "embedding_s3 = embedding_function.embed_query(\n",
        "    \"I prefer to play football\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hja5kK6daY3l"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hja5kK6daY3l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the embeddings have the same lenght despite the sentence length."
      ],
      "metadata": {
        "id": "0GfRJLVcaY3l"
      },
      "id": "0GfRJLVcaY3l"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\" embedding_s1 = {len(embedding_s1)}\n",
        " embedding_s2 =  {len(embedding_s2)}\n",
        " embedding_s3 =  {len(embedding_s3)}\"\"\")"
      ],
      "metadata": {
        "outputId": "10b67ab5-4cd0-4cc0-c1f9-6abc98cd1cf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FjwxUxTaY3m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " embedding_s1 = 384\n",
            " embedding_s2 =  384\n",
            " embedding_s3 =  384\n"
          ]
        }
      ],
      "id": "1FjwxUxTaY3m"
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 first positions of embedding_s1.\n",
        "print(embedding_s1[:5])\n",
        "print(embedding_s2[:5])\n",
        "print(embedding_s3[:5])"
      ],
      "metadata": {
        "outputId": "cb930085-c4fd-4bd5-ab15-c829be982c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi6MkKKYaY3m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.034526657313108444, 0.031680285930633545, -0.03841095045208931, 0.07523446530103683, -0.04117880389094353]\n",
            "[-0.009032496251165867, 0.014947249554097652, 0.06308788061141968, 0.06641353666782379, 0.03385470062494278]\n",
            "[0.01728087104856968, -0.019022813066840172, 0.011131912469863892, -0.003836166812106967, 0.03133479878306389]\n"
          ]
        }
      ],
      "id": "Pi6MkKKYaY3m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing SKLEARN to measure the cosine distances"
      ],
      "metadata": {
        "id": "MxoqDpLIaY3m"
      },
      "id": "MxoqDpLIaY3m"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn==1.2.2"
      ],
      "metadata": {
        "id": "fmS-ZYiHi7f-"
      },
      "id": "fmS-ZYiHi7f-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ntmp1iflaY3m"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ntmp1iflaY3m"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_s1_2d = np.array(embedding_s1).reshape(1, -1)\n",
        "embedding_s2_2d = np.array(embedding_s2).reshape(1, -1)\n",
        "embedding_s3_2d = np.array(embedding_s3).reshape(1, -1)"
      ],
      "metadata": {
        "id": "zWS2m7J3aY3m"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zWS2m7J3aY3m"
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_s1_2d[0][:5])"
      ],
      "metadata": {
        "outputId": "41b3933d-0713-4a06-8706-db4b1d1be0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEz0wqn_aY3m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.03452671  0.03168032 -0.03841094  0.07523444 -0.04117881]\n"
          ]
        }
      ],
      "id": "eEz0wqn_aY3m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "S1 sentence is more similar to S2 sentence than to S3 sentence. That is because the first sentences are talking about a healthier way of live."
      ],
      "metadata": {
        "id": "VCKP78yEaY3n"
      },
      "id": "VCKP78yEaY3n"
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(embedding_s1_2d, embedding_s2_2d))\n",
        "print(cosine_similarity(embedding_s1_2d, embedding_s3_2d))\n",
        "print(cosine_similarity(embedding_s2_2d, embedding_s3_2d))\n"
      ],
      "metadata": {
        "outputId": "bca12b77-e26a-462d-b966-47924d98a8c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcEhD2JGaY3n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.54180279]]\n",
            "[[0.16314688]]\n",
            "[[0.25131365]]\n"
          ]
        }
      ],
      "id": "PcEhD2JGaY3n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print embeddings"
      ],
      "metadata": {
        "id": "mncNTu_oe2i6"
      },
      "id": "mncNTu_oe2i6"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA for 2D visualization\n",
        "PCA_model = PCA(n_components = 2)"
      ],
      "metadata": {
        "id": "Jjculuboe1tA"
      },
      "id": "Jjculuboe1tA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_sentences=[]\n",
        "embeddings_sentences.append(embedding_s1)\n",
        "embeddings_sentences.append(embedding_s2)\n",
        "embeddings_sentences.append(embedding_s3)\n",
        "PCA_model.fit(embeddings_sentences)\n",
        "embeddings_coord = PCA_model.transform(embeddings_sentences)"
      ],
      "metadata": {
        "id": "HA_2tUU6hIoE"
      },
      "id": "HA_2tUU6hIoE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_coord)"
      ],
      "metadata": {
        "id": "rzKn5vd3iqQa",
        "outputId": "99cd1b3c-ba1c-44e1-ec83-4e39002ddbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rzKn5vd3iqQa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.46251847 -0.44190478]\n",
            " [-0.31148544  0.50339061]\n",
            " [ 0.77400391 -0.06148583]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x, y = zip(*embeddings_coord)\n",
        "\n",
        "# Name the points\n",
        "names = ['s1', 's2', 's3']\n",
        "# Colors\n",
        "colors = ['red', 'green', 'blue']\n",
        "\n",
        "for i, name in enumerate(names):\n",
        "    plt.scatter(x[i], y[i], marker='o', color=colors[i], label=name)\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L8Wbyjnyj3KU",
        "outputId": "7c109a88-b27f-4e54-9c2c-d9bf801655ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "id": "L8Wbyjnyj3KU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5387b3e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-12T22:01:56.993351Z",
          "iopub.status.busy": "2023-07-12T22:01:56.992775Z",
          "iopub.status.idle": "2023-07-12T22:01:57.001309Z",
          "shell.execute_reply": "2023-07-12T22:01:56.999431Z",
          "shell.execute_reply.started": "2023-07-12T22:01:56.993305Z"
        },
        "papermill": {
          "duration": 0.037288,
          "end_time": "2023-11-07T23:43:36.206248",
          "exception": false,
          "start_time": "2023-11-07T23:43:36.16896",
          "status": "completed"
        },
        "tags": [],
        "id": "c5387b3e"
      },
      "source": [
        "# Conclusions.\n",
        "Not a long notebook, but with a lot of content.\n",
        "\n",
        "We have used a vectorial database to store the information from a Kaggle dataset. We have incorporated it into a LangChain chain through a retriever, and now we are able to make queries about the information contained in the dataset to a couple of Hugging Face Language Models.\n",
        "\n",
        "And Also you've been introduce to LCEL!!!\n",
        "\n",
        "Please don't stop here.\n",
        "\n",
        "* The notebook is prepared to use two Datasets. Do tests with it.An if you have time select other Datset from Kaggle.\n",
        "\n",
        "* Find another model on Hugging Face and compare it.\n",
        "\n",
        "* We loaded the data from a Dataframe, try to upload Data from a .txt file.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3Dgo0ISVHhE"
      },
      "id": "M3Dgo0ISVHhE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 301.368093,
      "end_time": "2023-11-07T23:43:39.05917",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-07T23:38:37.691077",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}